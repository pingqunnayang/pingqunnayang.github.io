---
layout: post
title:  ELK杂记
titlename: ELK杂记
date:   2016-06-07 10:18:23 
category: 技术
tags: ELK log
description:
---
### 1.1 简介

<p style="text-indent: 2em">很早搭建了公司的日志查询、统计和报警平台，一直没有写blog记录下搭建的过程，以及中途出现的问题，最近公司要被合并，抽时间整理下技术。
ELK是由‎Elasticsearch + Logstash + Kibana组成的一套日志分析平台。

> logstash负责日志收集和分析。
> Elasticsearch 负责日志存储和查询。
> Kibana作为数据展现和报表统计。

### 1.2 数据流图

![Alt text](/public/img/technology/ELK-1.png)

<!-- more -->

> - logstash shipper端收集各个业务日志然后根据grok语法规则解析日志，发送到指定的kafka队列。
> - logstash indexer端从kafka指定队列接收日志，然后发送到ES中。
> - 访问kibana的界面，可以查看日志和分析日志并做报表展现。

### 1.3 logstash shipper
 Logstash 社区通常习惯用 shipper，broker 和 indexer 来描述数据流中不同进程各自的角色， Logstash的通用配置如下
 
```json
input {
}
# filter是可选配置
# filter {
#
# }
output {
} 
```

<p style="text-indent: 2em">Input、Output、Filter插件支持的类型和配置可以参考官方文档https://www.elastic.co/guide/en/logstash/current/pipeline.html，下面是我们项目的配置。我们格式化了所有API接口日志,Log4j打印的原始日志如下：

```json
2016-06-13 15:59:45,401 [DubboServerHandler-10.14.25.54:1936-thread-196] [module:dd-trade-server] [uuid:4b534c46-96da-4383-bdd3-146580487037] INFO  aop.EntranceGuarderAop (EntranceGuarderAop.java:117)     - clazz:com.****.trade.api.impl.SignedContractAPIImpl,method:getWholeContractPdf.request: CommonJsonRequest[paramJson={"contractId":"60619"},base=Base[accountId=905,accountType=1,token=1234,location=<null>,deviceId=<null>,deviceName=<null>,ip=123.121.221.228,appVersion=<null>,from=3,sign=<null>,appId=<null>,uuid=4b534c46-96da-4383-bdd3-146580487037,baseCityId=-1,timestamp=1465804870374,optId=<null>],param=<null>], response: CommonResponse[code=100000,message=操作成功,token=<null>,data=CommHtmlDTO[htmlContent=<null>,fileFetchCode=<null>,fileFetchUrl=372A.do,title=电脑打开打印合同，24小时有效,description=电脑打开此链接可打印,iconUrl=share_icon.png,hasAgreement=false,ownerMobile=13810010600],error=<null>], cost: 271ms
```

logstash shipper端的input、filter、output的配置如下：

```nginx
input {
     file {
         type => "dd-trade-service"
         path => ["/usr/local/dd-trade/data/instance-35/logs/dubbo-default.log"]
         exclude => ["*.gz", "access.log"]
         codec => multiline {
               pattern => "^\d{4}-\d{2}-\d{2}"
               negate => true
               what => "previous"
         }
    }
}
```

<p style="text-indent: 2em">logstash会收集dubbo-default.log的日志，`multiline`是解决一条异常日志多行的问题，异常日志会打出部分堆栈显示成多行，而logstash默认是按一行为一条消息发送到broker（Kafka），这样就使一条异常日志在broker中是多条消息，kibana上查看异常日志很不方便，所以我们会按时间匹配来区分是否是一条日志消息，当某条日志没有`"^\d{4}-\d{2}-\d{2}"`格式的时间时，我们就一直往下扫描，直到匹配上才当做一条消息发送给broker。

```nginx
filter {
    grok {
       match => [ 
	       "message","%{TIMESTAMP_ISO8601:TIMESTAMP}[\S\s]*%{IP:IP}[\S\s]* \[module:dd-(?<MODULE_NAME>\w+-server)\] \[uuid:%{UUID:UUID}] %{LOGLEVEL:LOG_LEVEL}[\s\S]*\- clazz\:(?<CLASS_PATH>\S*)\,method:(?<METHOD_NAME>\S*)\.[\S\s]*(?<=accountId=)(?<ACCOUNTID>\d*)[\S\s]*(?<=deviceId=)(?<DEVICEID>[\S\s][^\,]*)[\S\s]*(?<=from=)(?<FROM>\d*)[\s\S]*(?<=baseCityId=)(?<BASE_CITY>[\S\s][^\,]*)[\s\S]*(?<=code=)(?<CODE>[\d][^\,]*)[\s\S]*(?<=cost: )(?<COST>\d*)ms",
           "message","%{TIMESTAMP_ISO8601:TIMESTAMP}[\S\s]*\] (?<LOG_LEVEL>(ALERT|TRACE|DEBUG|INFO|WARN|ERROR)) "
                   ]
          add_field => [ "API", "%{CLASS_PATH}.%{METHOD_NAME}" ]
    }
    date {
        match => ["TIMESTAMP", "yyyy-MM-dd HH:mm:ss,SSS"]
        timezone => "Asia/Shanghai" 
        add_field => { "TIMESTAMP" => "%{@timestamp}" }
        remove_field => ["TIMESTAMP"]
    }
    mutate {
        convert => ["COST", "integer"]
    }
}
```

<p style="text-indent: 2em">使用grok filter来解析日志，这段配置会解析出Log4j日志中的BASE_CITY、COST等字段。<br>
`match`里面配置了多个message的正则表达式，是因为logstash的grok控件会从上往下匹配，只要匹配出一个就跳出，配置两个是为了满足部分非API的日志，当不能匹配第一个时可以用第二个解析出日志的时间和日志等级，方便alarm系统对ERROR日志报警处理。<br>
`date`配置是将grok匹配出的TIMESTAMP字段赋值给@timestamp字段，为什么要这么操作？因为logstash默认会为每条消息写入一个@timestamp字段为当前收集的时间，这个时间会影响到kibana的显示，这里我们把Log4j的时间作为logstash收集时间，这样Es在根据时间建立索引也比较准确，因为一天的日志就是一个索引。<br>
`mutate`配置是将grok解析出来的COST(耗时)段转换成integer类型，转换是因为grok解析出的都是string类型，不方便你后期对COST做报表统计，或者查询某个区间的请求数量。
链接是grok的debug地址：https://grokdebug.herokuapp.com/

```nginx
output {
    kafka {
        batch_num_messages => 10
        broker_list => "10.14.25.51:9092,10.14.25.52:9092,10.14.25.55:9092"
        queue_buffering_max_messages => 10000
        topic_id => "dubbo_service"
    }
}
```

output 是将grok解析完的日志发送到kafka。logstash还支持条件判断，如下配置：

```nginx
input {
    file {
       type => "dd-countly"
        path => ["/root/countly-server/log/countly-api.log"]
        exclude => ["*.gz", "access.log"]
        codec => multiline {
             pattern => "^\[\d{4}-\d{2}-\d{2}"
              negate => true
              what => "previous"
        }
     }
}
filter {
        grok {
           match => [
                "message","^\[%{TIMESTAMP_ISO8601:TIMESTAMP}] %{WORD:LOG_LEVEL}\:(?<MESSAGE> .*)"
            ]
		      remove_field => [ "message" ]
	     }
	      if [LOG_LEVEL] == "CRASH"{
             json{
                source => [MESSAGE]
			    remove_field => [ "MESSAGE"]
            }
            date {
                match => ["TIMESTAMP", "ISO8601"]
	            timezone => "Asia/Shanghai" 
			    add_field => { "TIMESTAMP" => "%{@timestamp}" }
                remove_field => ["TIMESTAMP"]
		     }
	  }
}
output {
     if [LOG_LEVEL] == "CRASH"{
        kafka {
            batch_num_messages => 100
            broker_list => "10.14.25.35:9092,10.14.25.49:9092,10.14.25.56:9092"
            queue_buffering_max_messages => 10000
            topic_id => "countly_service"
      }
   }
}
```

### 1.4 logstash indexer
indexer端的功能是从kafka中接收日志然后发送到elasticsearch中。配置如下：

```nginx
input {
 kafka {
        zk_connect => "10.14.25.35:2181,10.14.25.49:2181,10.14.25.56:2181"
        group_id => "elk_dubbo_service"
        topic_id => "dubbo_service"
        reset_beginning => false
        consumer_threads => 3
        queue_size => 1000
        rebalance_max_retries => 4
        rebalance_backoff_ms => 2000
        consumer_timeout_ms => -1
        consumer_restart_on_error => true
        consumer_restart_sleep_ms => 0
        codec => json
    }
}

output {
    elasticsearch { 
        hosts => ["10.14.25.51:9200","10.14.25.52:9200","10.14.25.55:9200"]
        index => "logstash-%{type}-%{+YYYY.MM.dd}"
    }
}
```

上面这段配置`input`中配置了从kafka中接收logstash收集的日志，`output`配置是将日志写入到elasticsearch中。

### 1.5 logstash broker
下面是经过shipper端解析后的日志格式，也是在kafka中的数据格式。

```json
{
  "_index": "logstash-dd-trade-service-2016.06.13", 
  "_type": "dd-trade-service",
  "_id": "AVVIxiGleBx8qBt_hH1v",
  "_score": null,
  "_source": {
    "@timestamp": "2016-06-13T07:59:45.401Z",
    "message": "原始日志，这里省略....",
    "@version": "1",
    "host": "IP-25-54",
    "path": "/usr/local/dd-trade/data/instance-35/logs/dubbo-default.log",
    "type": "dd-trade-service",
    "IP": "10.14.25.54",
    "MODULE_NAME": "trade-server",
    "UUID": "4b534c46-96da-4383-bdd3-146580487037",
    "LOG_LEVEL": "INFO",
    "CLASS_PATH": "com.***.trade.api.impl.SignedContractAPIImpl",
    "METHOD_NAME": "getWholeContractPdf",
    "ACCOUNTID": "905",
    "DEVICEID": "<null>",
    "REQ_IP": "123.121.221.228",
    "FROM": "3",
    "BASE_CITY": "-1",
    "CODE": "100000",
    "COST": 271,
    "API": "com.***.trade.api.impl.SignedContractAPIImpl.getWholeContractPdf"
  },
  "fields": {
    "@timestamp": [
      1465804785401
    ]
  },
  "sort": [
    1465804785401
  ]
}
```

|字段|值|备注|
| ------------- |:-------------:|:-----:|:-----:|
|_index|logstash-dd-trade-service-2016.06.13|索引名字| 
|_type|dd-trade-service|类型|
|_id|AVVIxiGleBx8qBt_hH1v|id|
|_source|****|文档|
表中的字段含义，是es中的特殊字段，`注意你的_source字段里面的Fileds不要用下划线作为开头，否则用kibana无法针对这个filed做查询`。

###1.6 ElasticSearch
Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎。Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）

```java
Relational DB -> Databases -> Tables -> Rows -> Columns
Elasticsearch -> Indices   -> Types  -> Documents -> Fields
```

参考文章：http://es.xiaoleilu.com/020_Distributed_Cluster/10_Cluster_health.html

###1.7 kibana
kibana的安装使用比较简单，安装完成后访问localhost:5601就可以查看日志、制作报表。 

![Alt text](/public/img/technology/ELK-2.png)

 
###1.8 问题

> 1. 我们用后端api的请求日志来统计每个接口的PV和UV，某天突然发现接口的UV和PV暴涨了将近一倍，各种排查日志，在kibana中发现晚上7~8点期间日志翻了将近10倍，第一反应就是有爬虫，结果分析日志发现日志都属于正常请求，再仔细看，发现7~8点间又收集了次今天全天的日志，导致日志翻倍，排查后发现是因为OP在上线时用的脚本，会先将当天日志拷贝到其他目录，然后再解压上线包，再将日志重新拷贝到原来的目录，而这时logstash会认为文件是新文件，于是全部重新收集日志。logstsh是通过sincedb来记录文件当前行数的，一旦文件有变动，就会导致新建sincedb，你可以通过设置sincedb_path来避免文件重命名等问题导致日志重复收集的问题。







    



